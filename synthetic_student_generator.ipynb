{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\udde0 Synthetic Student Data Generator\n", "\n", "This notebook walks through the process of generating synthetic student data using metadata and training a simple language model (e.g., GPT-2) to generate new records."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udce6 Install Dependencies (Uncomment if needed)\n", "# !pip install pandas numpy faker transformers torch datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "from faker import Faker\n", "import random\n", "import torch\n", "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n", "from datasets import Dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcc1 Define Metadata"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["metadata = {\n", "    \"student_id\": {\"type\": \"string\", \"pattern\": \"SID####\"},\n", "    \"first_name\": {\"type\": \"string\", \"source\": \"faker.first_name\"},\n", "    \"last_name\": {\"type\": \"string\", \"source\": \"faker.last_name\"},\n", "    \"age\": {\"type\": \"int\", \"range\": [16, 25]},\n", "    \"grade\": {\"type\": \"categorical\", \"values\": [\"A\", \"B\", \"C\", \"D\", \"F\"]},\n", "    \"gpa\": {\"type\": \"float\", \"range\": [2.0, 4.0]},\n", "    \"enrollment_status\": {\"type\": \"categorical\", \"values\": [\"enrolled\", \"dropped\", \"graduated\"]}\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udd16 Generate Synthetic Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fake = Faker()\n", "\n", "def generate_student_record(meta):\n", "    record = {}\n", "    for col, props in meta.items():\n", "        if props[\"type\"] == \"string\":\n", "            if props.get(\"pattern\") == \"SID####\":\n", "                record[col] = f\"SID{random.randint(1000, 9999)}\"\n", "            elif props.get(\"source\") == \"faker.first_name\":\n", "                record[col] = fake.first_name()\n", "            elif props.get(\"source\") == \"faker.last_name\":\n", "                record[col] = fake.last_name()\n", "        elif props[\"type\"] == \"int\":\n", "            record[col] = random.randint(*props[\"range\"])\n", "        elif props[\"type\"] == \"float\":\n", "            record[col] = round(random.uniform(*props[\"range\"]), 2)\n", "        elif props[\"type\"] == \"categorical\":\n", "            record[col] = random.choice(props[\"values\"])\n", "    return record\n", "\n", "def generate_dataset(meta, num_rows=500):\n", "    return pd.DataFrame([generate_student_record(meta) for _ in range(num_rows)])\n", "\n", "df = generate_dataset(metadata)\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\uddf9 Prepare Text for Tokenization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Format dataset for language model training\n", "df[\"text\"] = df.apply(lambda row: \", \".join([f\"{col}: {val}\" for col, val in row.items()]), axis=1)\n", "dataset = Dataset.from_pandas(df[[\"text\"]])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udde0 Tokenize and Train GPT-2 Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_name = \"gpt2\"\n", "tokenizer = AutoTokenizer.from_pretrained(model_name)\n", "tokenizer.pad_token = tokenizer.eos_token\n", "\n", "def tokenize_function(examples):\n", "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=64)\n", "\n", "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n", "\n", "model = AutoModelForCausalLM.from_pretrained(model_name)\n", "\n", "training_args = TrainingArguments(\n", "    output_dir=\"./synthetic_student_model\",\n", "    evaluation_strategy=\"epoch\",\n", "    per_device_train_batch_size=8,\n", "    num_train_epochs=3,\n", "    logging_dir='./logs',\n", "    logging_steps=500,\n", "    save_steps=10_000\n", ")\n", "\n", "trainer = Trainer(\n", "    model=model,\n", "    args=training_args,\n", "    train_dataset=tokenized_dataset,\n", "    tokenizer=tokenizer,\n", ")\n", "\n", "trainer.train()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\uddea Generate Example Records"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def generate_student(prompt=\"Student record:\", max_new_tokens=50):\n", "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n", "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n", "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n", "\n", "print(generate_student())"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11"}}, "nbformat": 4, "nbformat_minor": 5}